{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11467599,"sourceType":"datasetVersion","datasetId":7186326}],"dockerImageVersionId":31012,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\ntrain = pd.read_csv('/kaggle/input/titanic/train.csv')\ntrain['Title'] = train['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntitle_age_median = train.groupby('Title')['Age'].median()\n\n#print(title_age_median)\ntrain['Age'] = train.apply(lambda row: title_age_median[row['Title']] if pd.isna(row['Age']) else row['Age'], axis=1)\n# Define age bins and labels\nage_bins = [0, 5, 12, 18, 30, 45, 60, 75, 100]\nage_labels = ['0-5', '5-12', '12-18', '18-30', '30-45', '45-60', '60-75', '76+']\n\n# Create AgeGroup column\ntrain['AgeGroup'] = pd.cut(train['Age'], bins=age_bins, labels=age_labels, right=False)\n\n#Create Family Size\ntrain['Familysize'] = train['SibSp'] + train['Parch'] + 1\ntrain['isalone'] = (train['Familysize'] == 1).astype(int)\ntrain['Sex'] = train['Sex'].map({'male' : 1 , 'female' : 0})\n\ndef family_group(size):\n    if size == 1:\n        return 'Solo'\n    elif size <= 3:\n        return 'Small'\n    elif size <= 5:\n        return 'Medium'\n    else:\n        return 'Large'\n\n#Create Family Group \ntrain['FamilyGroup'] = train['Familysize'].apply(family_group)\n\n#Create Fare is missing\nage_pclass_embarked_fare = train.groupby(['AgeGroup', 'Pclass', 'Embarked'])['Fare'].median().to_dict()\n# Fill missing Fare based on AgeGroup, Pclass, and Embarked using the tuple key\ntrain['Fare'] = train.apply(\n    lambda row: age_pclass_embarked_fare.get((row['AgeGroup'], row['Pclass'], row['Embarked']), row['Fare']) \n    if pd.isna(row['Fare']) else row['Fare'], axis=1\n)\n\n#Fare Bins:\nn_bins = 4\ntrain['FareGroup'] = pd.qcut(train['Fare'], q=n_bins, labels=['Low', 'Medium', 'High', 'Expensive'])\n\n\nX = train.drop(['Survived', 'PassengerId', 'Name', 'Cabin', 'Ticket','SibSp','Parch','isalone'], axis=1)\nY = train['Survived']\n#print(X.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T06:41:34.112024Z","iopub.execute_input":"2025-04-19T06:41:34.112401Z","iopub.status.idle":"2025-04-19T06:41:34.182965Z","shell.execute_reply.started":"2025-04-19T06:41:34.112378Z","shell.execute_reply":"2025-04-19T06:41:34.182010Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/4075373705.py:38: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  age_pclass_embarked_fare = train.groupby(['AgeGroup', 'Pclass', 'Embarked'])['Fare'].median().to_dict()\n","output_type":"stream"}],"execution_count":165},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/titanic/test.csv')\ntest['Title'] = test['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n\n#print(title_age_median)\ntest['Age'] = test.apply(lambda row: title_age_median[row['Title']] if pd.isna(row['Age']) else row['Age'], axis=1)\n\n# Define age bins and labels\nage_bins = [0, 5, 12, 18, 30, 45, 60, 75, 100]\nage_labels = ['0-5', '5-12', '12-18', '18-30', '30-45', '45-60', '60-75', '76+']\n\n# Create AgeGroup column\ntest['AgeGroup'] = pd.cut(test['Age'], bins=age_bins, labels=age_labels, right=False)\n\n#Create Family Size\ntest['Familysize'] = test['SibSp'] + test['Parch'] + 1\ntest['isalone'] = (test['Familysize'] == 1).astype(int)\ntest['Sex'] = test['Sex'].map({'male' : 1 , 'female' : 0})\n\n#Create Family Group \ntest['FamilyGroup'] = test['Familysize'].apply(family_group)\n\n# Fill missing Fare based on AgeGroup, Pclass, and Embarked using the tuple key\ntest['Fare'] = test.apply(\n    lambda row: age_pclass_embarked_fare.get((row['AgeGroup'], row['Pclass'], row['Embarked']), row['Fare']) \n    if pd.isna(row['Fare']) else row['Fare'], axis=1\n)\n\n#Fare Bins:\nn_bins = 4\ntest['FareGroup'] = pd.qcut(test['Fare'], q=n_bins, labels=['Low', 'Medium', 'High', 'Expensive'])\n\nXt = test.drop(['PassengerId', 'Name', 'Cabin', 'Ticket','SibSp','Parch','isalone'], axis=1)\nprint(Xt.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T06:51:08.065418Z","iopub.execute_input":"2025-04-19T06:51:08.065782Z","iopub.status.idle":"2025-04-19T06:51:08.116678Z","shell.execute_reply.started":"2025-04-19T06:51:08.065760Z","shell.execute_reply":"2025-04-19T06:51:08.115498Z"}},"outputs":[{"name":"stdout","text":"   Pclass  Sex   Age     Fare Embarked Title AgeGroup  Familysize FamilyGroup  \\\n0       3    1  34.5   7.8292        Q    Mr    30-45           1        Solo   \n1       3    0  47.0   7.0000        S   Mrs    45-60           2       Small   \n2       2    1  62.0   9.6875        Q    Mr    60-75           1        Solo   \n3       3    1  27.0   8.6625        S    Mr    18-30           1        Solo   \n4       3    0  22.0  12.2875        S   Mrs    18-30           3       Small   \n\n  FareGroup  \n0       Low  \n1       Low  \n2    Medium  \n3    Medium  \n4    Medium  \n","output_type":"stream"}],"execution_count":173},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n\nfor col in ['Title','FareGroup', 'Embarked','FamilyGroup','AgeGroup','Fare']:\n    X_train[col] = X_train[col].astype('category')\n    X_val[col] = X_val[col].astype('category')\n    Xt[col] = Xt[col].astype('category')","metadata":{"trusted":true},"outputs":[],"execution_count":184},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV, train_test_split\nfrom sklearn.metrics import accuracy_score\nimport pandas as pd\n\n# One-hot encode categorical columns\nX_encoded = pd.get_dummies(X, drop_first=True)\n\n# Split the dataset\nX_train, X_val, y_train, y_val = train_test_split(X_encoded, Y, test_size=0.2, random_state=42)\n\n# Random Forest model\nrf = RandomForestClassifier(random_state=42)\n\n# Hyperparameter tuning\nparam_grid = {\n    'n_estimators': [100, 200, 300, 500],\n    'max_depth': [None, 5, 10, 20],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4],\n    'max_features': ['sqrt', 'log2'],\n    'bootstrap': [True, False]\n}\n\nrandom_search = RandomizedSearchCV(\n    estimator=rf,\n    param_distributions=param_grid,\n    n_iter=500,\n    cv=10,\n    verbose=1,\n    random_state=42,\n    n_jobs=-1\n)\n\nrandom_search.fit(X_train, y_train)\n\n# Evaluate\nprint(\"Best Parameters:\", random_search.best_params_)\nbest_model = random_search.best_estimator_\ny_pred = best_model.predict(X_val)\nprint(\"Improved Accuracy:\", accuracy_score(y_val, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T07:09:47.644961Z","iopub.execute_input":"2025-04-19T07:09:47.645281Z"}},"outputs":[{"name":"stdout","text":"Fitting 10 folds for each of 500 candidates, totalling 5000 fits\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nimport pandas as pd\n\n\n# Identify categorical and numerical columns\ncategorical_features = ['Title','FareGroup', 'Embarked','FamilyGroup','AgeGroup']\nnumerical_features = ['Pclass', 'Age', 'Sex', 'Fare', 'Familysize']\n\n# Define preprocessing steps\npreprocessor = ColumnTransformer(transformers=[\n    ('num', StandardScaler(), numerical_features),\n    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n])\n\n# Create pipeline\npipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('classifier', SVC(kernel='rbf', C=1, gamma='scale'))\n])\n\n\nparam_grid = {\n    'classifier__C': [0.1, 1, 10, 100],\n    'classifier__kernel': ['linear', 'rbf'],\n    'classifier__gamma': ['scale', 0.01, 0.1, 1],\n    'classifier__class_weight': [None, 'balanced']\n}\n\n\n# Train/Val split\nX_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.1, random_state=42)\n\n# Train the model\ngrid_search = GridSearchCV(pipeline, param_grid, cv=5, verbose=1, n_jobs=-1)\ngrid_search.fit(X_train, y_train)\n\nprint(\"Best Params:\", grid_search.best_params_)\nprint(\"Best Accuracy:\", grid_search.best_score_)\n\n# Predict\n# Now use best estimator (the fitted pipeline)\nbest_pipeline = grid_search.best_estimator_\ny_pred = best_pipeline.predict(X_val)\n\n# Evaluate\nprint(\"SVM Accuracy with Categorical Handling:\", accuracy_score(y_val, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T07:08:16.245956Z","iopub.execute_input":"2025-04-19T07:08:16.246334Z","iopub.status.idle":"2025-04-19T07:09:06.500634Z","shell.execute_reply.started":"2025-04-19T07:08:16.246310Z","shell.execute_reply":"2025-04-19T07:09:06.499658Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 64 candidates, totalling 320 fits\nBest Params: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__gamma': 'scale', 'classifier__kernel': 'rbf'}\nBest Accuracy: 0.8376940993788822\nSVM Accuracy with Categorical Handling: 0.8444444444444444\n","output_type":"stream"}],"execution_count":189},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\nfrom xgboost import XGBClassifier\nimport numpy as np\n\n# Base model\nxgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', tree_method='hist', enable_categorical=True)\n\n# Parameter grid\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [3, 5, 7, 10],\n    'learning_rate': [0.01, 0.05, 0.1, 0.3],\n    'subsample': [0.6, 0.8, 1.0],\n    'colsample_bytree': [0.6, 0.8, 1.0],\n    'gamma': [0, 1, 5],\n    'reg_alpha': [0, 0.1, 1],\n    'reg_lambda': [1, 1.5, 2]\n}\n\n# Randomized Search\nrandom_search = RandomizedSearchCV(\n    estimator=xgb,\n    param_distributions=param_grid,\n    n_iter=100,  # increase for better results\n    cv=5,\n    verbose=1,\n    random_state=42,\n    n_jobs=-1\n)\n\n# Fit to training data\nrandom_search.fit(X_train, y_train)\n\n# Best parameters and accuracy\nprint(\"Best Parameters:\", random_search.best_params_)\nbest_model = random_search.best_estimator_\n\n# Evaluate\ny_pred = best_model.predict(X_val)\nprint(\"Improved Accuracy:\", accuracy_score(y_val, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T07:04:07.485203Z","iopub.execute_input":"2025-04-19T07:04:07.485552Z","iopub.status.idle":"2025-04-19T07:04:30.036844Z","shell.execute_reply.started":"2025-04-19T07:04:07.485529Z","shell.execute_reply":"2025-04-19T07:04:30.035704Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 100 candidates, totalling 500 fits\nBest Parameters: {'subsample': 1.0, 'reg_lambda': 2, 'reg_alpha': 1, 'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.3, 'gamma': 5, 'colsample_bytree': 1.0}\nImproved Accuracy: 0.6703910614525139\n","output_type":"stream"}],"execution_count":186},{"cell_type":"code","source":"print(\"Model Prediction Starts\")\nyt = best_pipeline.predict(Xt)\nprint(\"Model Prediction Ends\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T07:05:30.079543Z","iopub.execute_input":"2025-04-19T07:05:30.079885Z","iopub.status.idle":"2025-04-19T07:05:30.107390Z","shell.execute_reply.started":"2025-04-19T07:05:30.079864Z","shell.execute_reply":"2025-04-19T07:05:30.105928Z"}},"outputs":[{"name":"stdout","text":"Model Prediction Starts\nModel Prediction Ends\n","output_type":"stream"}],"execution_count":187},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'PassengerId': test['PassengerId'],\n    'Survived': yt\n})\n\nsubmission.to_csv('/kaggle/working/submission3.csv', index=False)\nprint(\"File written to output\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T07:05:40.899677Z","iopub.execute_input":"2025-04-19T07:05:40.900015Z","iopub.status.idle":"2025-04-19T07:05:40.909372Z","shell.execute_reply.started":"2025-04-19T07:05:40.899992Z","shell.execute_reply":"2025-04-19T07:05:40.908269Z"}},"outputs":[{"name":"stdout","text":"File written to output\n","output_type":"stream"}],"execution_count":188}]}